{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b4333cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8c8847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose one or multiple indicators.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242076f2351d4190acc370d4a9b2ffb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Options:', layout=Layout(height='300px', width='30%'), options=('ADP_Employment_Châ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind_files = sorted(glob.glob(\"Data_Copy/Economic Indicators/*.csv\"))\n",
    "ind_names = [i[73:] for i in ind_files]\n",
    "print(\"Choose one or multiple indicators.\")\n",
    "w = widgets.SelectMultiple(\n",
    "    options=ind_names,\n",
    "    description='Options:',\n",
    "    disable=False,\n",
    "    layout=Layout(width='30%', height='300px')\n",
    ")\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb705dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['historical_country_United_States_indicator_Terms_of_Trade.csv',\n",
       " 'historical_country_United_States_indicator_Terrorism_Index.csv',\n",
       " 'historical_country_United_States_indicator_Total_Vehicle_Sales.csv',\n",
       " 'historical_country_United_States_indicator_Tourism_Revenues.csv',\n",
       " 'historical_country_United_States_indicator_Tourist_Arrivals.csv',\n",
       " 'historical_country_United_States_indicator_Unemployed_Persons.csv',\n",
       " 'historical_country_United_States_indicator_Unemployment_Rate.csv',\n",
       " 'historical_country_United_States_indicator_Wage_Growth.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_files_used = w.value\n",
    "start = \"historical_country_United_States_indicator_\"\n",
    "indicators = [start+str(x) for x in ind_files_used]\n",
    "indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1d746",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c1e9c",
   "metadata": {},
   "source": [
    "The purpose of the following cell is to list all the available economic indicators that we will use as features in our modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa7a186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indicatorIdxs = []\n",
    "for indicator_file in glob.glob(\"Data_Copy/Economic indicators/*\"):\n",
    "    print(indicator_file)\n",
    "    indi_cols = list(pd.read_csv(indicator_file).columns)\n",
    "    if indi_cols.index('Value'):\n",
    "        indicatorIdxs.append(indi_cols.index('Value'))\n",
    "    else:\n",
    "        sys.exit(0)\n",
    "    print(indi_cols, end=\"\\n\"+\"-\"*len(str(indi_cols))+\"\\n\")\n",
    "print(\"Num Indicators:\", len(indicatorIdxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eaff71",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = {\"JAN\":1, \"FEB\":2, \"MAR\":3, \"APR\":4, \"MAY\":5, \"JUN\":6, \n",
    "          \"JUL\":7, \"AUG\":8, \"SEP\":9, \"OCT\":10, \"NOV\":11, \"DEC\":12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dates(dataframe, startYear, endYear, startMonth, endMonth):\n",
    "    \"\"\"\n",
    "    Create Dense neural network model for evaluating each indicator's explanatory strength\n",
    "    \n",
    "    inputs\n",
    "    --\n",
    "    dataframe (pd.DataFrame())\n",
    "    startYear (int) : starting year of the data (ex. 2009)\n",
    "    endYear (int) : ending year of the data (ex. 2021)\n",
    "    startMonth (int) : index of the month (1 is january, 12 is december)\n",
    "    endMonth (int) :  index of the month (1 is january, 12 is december)\n",
    "    \n",
    "    \n",
    "    outputs\n",
    "    --\n",
    "    modified dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "#     if \"Month\" and \"Year\" in dataframe.columns:\n",
    "#         dataframe[\"Indicator\"] = 0\n",
    "#         return dataframe\n",
    "    \n",
    "    # Initialize lists for new columns in DataFrame\n",
    "    columnMonth = []\n",
    "    columnYear = []\n",
    "    columnIndicator = []\n",
    "    # Append year, month, and empty indicator values for each remaining month in the first year\n",
    "    for p in range(startMonth, 13):\n",
    "        columnMonth.append(p)\n",
    "        columnYear.append(startYear)\n",
    "        columnIndicator.append(0)\n",
    "    # Append year, month, and empty indicator value for each month in the remaining years (besides the last)\n",
    "    for x in range(startYear + 1, endYear):\n",
    "        for i in range(1, 13):\n",
    "            columnMonth.append(i)\n",
    "            columnYear.append(x)\n",
    "            columnIndicator.append(0)\n",
    "    # Append year, month, and empty indicator value for the remaining months in the last year\n",
    "    for r in range(1, endMonth + 1):\n",
    "        columnMonth.append(r)\n",
    "        columnYear.append(endYear)\n",
    "        columnIndicator.append(0)\n",
    "    # Add the year, month, and empty indicator columns to the original dataset\n",
    "    dataframe['Year'] = columnYear\n",
    "    dataframe['Month'] = columnMonth\n",
    "    dataframe['Indicator'] = columnIndicator\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c1b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(numNodes, includeIndicator=True, activation='relu',\n",
    "                 optimizer='adam', loss='mean_squared_error'):\n",
    "    \"\"\"\n",
    "    Create Dense neural network model for evaluating each indicator's explanatory strength\n",
    "    \n",
    "    inputs\n",
    "    --\n",
    "    numNodes (int) : baseline number of nodes used for constructing the neural network layers\n",
    "    includeIndicator (bool) : Used to mark whether a model is fitted with an indicator feature\n",
    "    activation, optimizer, loss (string) : Tensorflow neural network parameters\n",
    "    \n",
    "    outputs\n",
    "    --\n",
    "    model (tf.keras.Model()) : neural network model\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(numNodes*5/3, activation = activation, input_dim=2+int(includeIndicator))) # increase input_dim\n",
    "#     model.add(Dense(numNodes*2/3, activation = activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(numNodes*1/3, activation = activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "    return model\n",
    "\n",
    "# TODO: add parameters for input size, num layers, etc.\n",
    "def train_and_test(dataframe, trainYears, testYear, indexOfIndicator, \n",
    "                   indicatorData, numNodes, SalesColName, includeIndicator):\n",
    "    \"\"\"\n",
    "    Train and test neural network on data\n",
    "    \n",
    "    inputs\n",
    "    --\n",
    "    dataframe (pd.DataFrame()) : dataset used for inputs into model\n",
    "    trainYears : used for assigning training/testing partitions\n",
    "    testYear : used for assigning training/testing partitions\n",
    "    indexOfIndicator (int) : the index of the indicator value\n",
    "    indicatorData : DataFrame/Series of indicator values for each time period\n",
    "    numNodes (int) : baseline number of nodes used for constructing the neural network layers\n",
    "    SalesColName (string) : the name of the sales column used by the dataframe parameter variable\n",
    "    includeIndicator (bool) : Used to mark whether a model is fitted with an indicator feature\n",
    "    \n",
    "    outputs\n",
    "    --\n",
    "    trainStDev (float) : standard deviation of the training data\n",
    "    testRMSE : root mean squared error of the model predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    # dataframe with an index 0 to length - 1, sales as the first column, followed by year, and month\n",
    "    # not optimized for multiple indicators yet, will continue updating for multiple indicator\n",
    "    if includeIndicator:\n",
    "        features = ['Sales', 'Year', 'Month', 'Indicator']\n",
    "        IndicatorValues = indicatorData.iloc[:, indexOfIndicator]\n",
    "        dataframe['Indicator'] = IndicatorValues\n",
    "    else:\n",
    "        features = ['Sales', 'Year', 'Month']\n",
    "    \n",
    "    # preprocess training data\n",
    "    dataframe[\"Sales\"] = dataframe[SalesColName]\n",
    "    if SalesColName != \"Sales\":\n",
    "        dataframe = dataframe.drop(SalesColName, axis=1)\n",
    "    \n",
    "    # assign testing data\n",
    "    testData = dataframe.loc[dataframe['Year'] == testYear]\n",
    "    testData = testData.reset_index()\n",
    "    testData = testData[features] # add 'UnemploymentRateValues'\n",
    "    \n",
    "    # assign training data\n",
    "    trainYearIdx = dataframe['Year'].apply(lambda x: any([x==ty for ty in trainYears]))\n",
    "    trainData = dataframe.loc[trainYearIdx]\n",
    "    trainData = trainData.reset_index()\n",
    "    trainData = trainData[features] # add 'UnemploymentRateValues'\n",
    "    \n",
    "    # Isolate training and test sets\n",
    "    X = trainData.iloc[:, 1:3+int(includeIndicator)] # increase index\n",
    "    Y = trainData.iloc[:, 0]\n",
    "    \n",
    "    Xi_Test = testData.iloc[:, 1:3+int(includeIndicator)] # increase index\n",
    "    Yi_Test = testData.iloc[:, 0]\n",
    "    XTrain, XTest, YTrain, YTest = train_test_split(X, Y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "    # Create and Fit Model\n",
    "    model = create_model(numNodes, includeIndicator)\n",
    "    model.fit(XTrain, YTrain, epochs=500, batch_size=128, verbose=0) #change batch size to a variable\n",
    "    \n",
    "    # Test results from model using training data\n",
    "    YPreds = model.predict(XTest)\n",
    "    try:\n",
    "        testRMSE = mean_squared_error(YTest, YPreds, squared=False)\n",
    "        trainStDev = trainData['Sales'].std()\n",
    "    except:\n",
    "        return np.nan, np.nan\n",
    "    return trainStDev, testRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b2095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(data, indicatorData, indexOfIndicator, salesColumn, trainYears, testYear, \n",
    "                 numNodes, startYear, endYear, startMonth, endMonth, includeIndicator):\n",
    "    \n",
    "    \"\"\"\n",
    "    parameters are a combination of the add_dates() and train_and_test()\n",
    "    \"\"\"\n",
    "    dataNew = pd.DataFrame(data)\n",
    "    # specify your sales column. New is my sales in this case #5\n",
    "    if \"Month\" not in dataNew and \"Year\" not in dataNew:\n",
    "        dataNew = dataNew[[salesColumn]]\n",
    "        # specify start year, end year, start month, end month\n",
    "        dataNew = add_dates(dataNew, startYear, endYear, startMonth, endMonth)\n",
    "    else:\n",
    "        dataNew = dataNew[[salesColumn, \"Month\", \"Year\"]]\n",
    "    #the data now has 3 columns: Sales, Month, Year, indicator (all 0s won't make a difference)\n",
    "    StDev, testRMSE = train_and_test(dataNew, trainYears, testYear,\n",
    "                                     indexOfIndicator, indicatorData, \n",
    "                                     numNodes, salesColumn, includeIndicator)\n",
    "    return StDev, testRMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d7111",
   "metadata": {},
   "source": [
    "### Feature engineering ideas\n",
    "    - inverse years from current year (years closer to test year should be weighted more heavily)\n",
    "    - one-hot encoded month and possibly day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9bd77",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be9bf89",
   "metadata": {},
   "source": [
    "## Costco Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfdb447",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Costco_Monthly = pd.read_csv(\"Data_Copy/Costco_Monthly Sales from 2012 to 2021.csv\", header=0)\n",
    "Costco_Monthly[\"Day\"] = Costco_Monthly.Date.apply(lambda x: int(x.split(\"-\")[0]))\n",
    "Costco_Monthly = Costco_Monthly.drop([\"Date\"], axis=1)\n",
    "Costco_Monthly = Costco_Monthly.dropna()\n",
    "Costco_Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d0b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numNodes = 153 # approx 2/3 of the number of your rows. Make this divisible by a three #6\n",
    "start = time.time()\n",
    "SalesColName = \"Net Sales (billions)\"\n",
    "TestYears = [2018, 2019, 2020]\n",
    "startYear = 2002 # 7\n",
    "endYear = 2021 # 8\n",
    "startMonth = 1 # 9\n",
    "endMonth = 4 # 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcdda06",
   "metadata": {},
   "source": [
    "# With Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821ac843",
   "metadata": {},
   "outputs": [],
   "source": [
    "includeIndicator = True\n",
    "resultsCostco = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943cc3bb",
   "metadata": {},
   "source": [
    "Loops through all the economic indicators and for each one, trains a model and evaluates its explained variance ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Costco_Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, indicator_file in enumerate(glob.glob(\"Data_Copy/Economic indicators/*\")):\n",
    "    print(i+1, \"_\".join(indicator_file.split(\"/\")[-1].split(\"_\")[5:])[:-4])\n",
    "    indexOfIndicator = indicatorIdxs[i]\n",
    "    indicatorData = pd.read_csv(indicator_file)\n",
    "    for TestYear in TestYears:\n",
    "        TrainYears = list(range(startYear,TestYear))\n",
    "        trainStDev, testRMSE = train_and_test(Costco_Monthly, TrainYears, TestYear, indexOfIndicator, \n",
    "                                              indicatorData, numNodes, SalesColName, includeIndicator)\n",
    "        currResults = {\n",
    "            \"Train Years\": f\"[{TrainYears[0]} ... {TrainYears[-1]}]\",\n",
    "            \"Pred Year\": int(TestYear),\n",
    "            \"Indicator\": indicator_file.split(\"/\")[-1],\n",
    "            \"Train StDev\": round(trainStDev, 3), \n",
    "            \"Test RMSE\": round(testRMSE, 3),\n",
    "            \"Explained Variance Ratio\": round((trainStDev - testRMSE) / trainStDev, 3)\n",
    "        }\n",
    "        resultsCostco = resultsCostco.append(currResults, ignore_index=True)\n",
    "\n",
    "print(\"Time elapsed:\", time.time()-start)            \n",
    "resultsCostco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe409542",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsCostco.sort_values(by=\"Explained Variance Ratio\").dropna().tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13287398",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsCostco.to_csv(\"Results/resultsCostco.csv\")\n",
    "resultsCostco.sort_values(by=\"Explained Variance Ratio\").to_csv(\"Results/resultsCostco_sorted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21797464",
   "metadata": {},
   "source": [
    "# Without Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "includeIndicator = False\n",
    "SalesColName = \"Net Sales (billions)\"\n",
    "resultsCostcoNoInd = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe8e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for TestYear in TestYears:\n",
    "    TrainYears = list(range(startYear,TestYear))\n",
    "    trainStDev, testRMSE = train_and_test(Costco_Monthly, TrainYears, TestYear, \"\", \n",
    "                                             \"\", numNodes, SalesColName, includeIndicator)\n",
    "    currResults = {\n",
    "        \"Train Years\": f\"[{TrainYears[0]} ... {TrainYears[-1]}]\",\n",
    "        \"Pred Year\": int(TestYear),\n",
    "        \"Indicator\": indicator_file.split(\"/\")[-1],\n",
    "        \"trainStDev\": round(trainStDev, 3), \n",
    "        \"Test RMSE\": round(testRMSE, 3),\n",
    "        \"Explained Variance Ratio\": round((trainStDev - testRMSE) / trainStDev, 3)\n",
    "    }\n",
    "    resultsCostcoNoInd = resultsCostcoNoInd.append(currResults, ignore_index=True)\n",
    "\n",
    "print(\"Time elapsed:\", time.time()-start)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7169c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultsCostcoNoInd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c5d4666",
   "metadata": {},
   "source": [
    "resultsCostcoNoInd.to_csv(\"Results/resultsCostcoNoInd.csv\")\n",
    "resultsCostcoNoInd.sort_values(by=\"Explained Variance Ratio\").to_csv(\"Results/resultsCostcoNoInd_sorted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2827ee",
   "metadata": {},
   "source": [
    "## Maryland Vehicles Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eee73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SalesDataSet = pd.read_pickle('Data/MarylandVehicleSales2002-2021')\n",
    "SalesDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a1aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IndexColumnOfIndicator = 2 #which index is your indicator columns #3\n",
    "SalesColumnName = 'New' # specify your sales column. New is my sales in this case #4\n",
    "TestYears = [2018, 2019, 2020] #5\n",
    "NumNodes = 153 # approx 2/3 of the number of your rows. Make this divisible by a three #6\n",
    "startYear = 2002 # 7\n",
    "endYear = 2021 # 8\n",
    "startMonth = 1 # 9\n",
    "endMonth = 4 # 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e242fe4",
   "metadata": {},
   "source": [
    "# With Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac54e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "includeIndicators = True\n",
    "resultsVehicles = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5150e801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i, indicator_file in enumerate(glob.glob(\"Data_CopyData/Economic indicators/*\")):\n",
    "    print(\"\\n----------\\n\\n\"+indicator_file.split(\"/\")[-1])\n",
    "    dataframe = SalesDataSet.copy()\n",
    "    \n",
    "    IndicatorDataSet = pd.read_csv(indicator_file)\n",
    "    IndexColumnOfIndicator = indicatorIdxs[i] - 1 # adjust for when DateTime is set as index\n",
    "    IndicatorDataSetDates = IndicatorDataSet['DateTime']\n",
    "    IndicatorDataSetDates = IndicatorDataSetDates.apply(lambda x: x[0:10])\n",
    "    IndicatorDataSet['DateTime'] = IndicatorDataSetDates\n",
    "    \n",
    "    IndicatorDataSet = IndicatorDataSet.set_index('DateTime')\n",
    "    IndicatorDataSet = IndicatorDataSet.loc['2002-01-30':'2021-04-30']\n",
    "    IndicatorDataSet.reset_index(drop=True, inplace = True)\n",
    "    \n",
    "    for TestYear in TestYears:\n",
    "        TrainYears = list(range(startYear,TestYear))\n",
    "        trainStDev, testRMSE = run_pipeline(SalesDataSet, IndicatorDataSet, IndexColumnOfIndicator, \n",
    "                                            SalesColumnName, TrainYears, TestYear,\n",
    "                                            NumNodes, startYear, endYear, startMonth,\n",
    "                                            endMonth, includeIndicators)\n",
    "        currResults = {\n",
    "            \"Train Years\": f\"[{TrainYears[0]} ... {TrainYears[-1]}]\",\n",
    "            \"Pred Year\": int(TestYear),\n",
    "            \"Indicator\": indicator_file.split(\"/\")[-1], \n",
    "            \"Train StDev\": round(trainStDev, 3), \n",
    "            \"Test RMSE\": round(testRMSE, 3),\n",
    "            \"Explained Variance Ratio\": round((trainStDev - testRMSE) / trainStDev, 3)\n",
    "        }\n",
    "        resultsVehicles = resultsVehicles.append(currResults, ignore_index=True)\n",
    "\n",
    "print(\"Time elapsed:\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c6f53d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "resultsVehicles"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8cdeab01",
   "metadata": {},
   "source": [
    "resultsVehicles.to_csv(\"Results/resultsVehicles.csv\")\n",
    "resultsVehicles.sort_values(by=\"Explained Variance Ratio\").to_csv(\"Results/resultsVehicles_sorted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd8219",
   "metadata": {},
   "source": [
    "# Without Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b69dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "includeIndicators = False\n",
    "resultsVehiclesNoInd = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61901b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for TestYear in TestYears:\n",
    "    TrainYears = list(range(startYear,TestYear))\n",
    "    trainStDev, testRMSE = train_and_test(SalesDataSet, [], \"\", \n",
    "                             SalesColumnName, TrainYears, TestYear,\n",
    "                             NumNodes, startYear, endYear, startMonth, endMonth,\n",
    "                             includeIndicators)\n",
    "    currResults = {\n",
    "        \"Train Years\": f\"[{TrainYears[0]} ... {TrainYears[-1]}]\",\n",
    "        \"Pred Year\": int(TestYear),\n",
    "        \"Train Std\": round(trainStDev, 3), \n",
    "        \"Test RMSE\": round(testRMSE, 3),\n",
    "        \"Explained Variance Ratio\": round((trainStDev - testRMSE) / trainStDev, 3)\n",
    "    }\n",
    "    resultsVehiclesNoInd = resultsVehiclesNoInd.append(currResults, ignore_index=True)\n",
    "\n",
    "print(\"Time elapsed:\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02359f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultsVehiclesNoInd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "996ae18e",
   "metadata": {},
   "source": [
    "resultsVehiclesNoInd.to_csv(\"Results/resultsVehiclesNoInd.csv\")\n",
    "resultsVehiclesNoInd.sort_values(by=\"Explained Variance Ratio\").to_csv(\"Results/resultsVehiclesNoInd_sorted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb953aa8",
   "metadata": {},
   "source": [
    "# MRTS Sales Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459bfac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mrts_data = pd.read_csv(\"Data_Copy/mrtssales_92-present.csv\")\n",
    "mrts_data['Date'] = mrts_data.iloc[:,0].apply(lambda x: x.replace(\".\", \"\"))\n",
    "mrts_data[\"Month\"] = mrts_data[\"Date\"].apply(lambda x: x[:3].upper()).tolist()\n",
    "mrts_data[\"Year\"] = mrts_data[\"Date\"].apply(lambda x: x[4:].upper()).tolist()\n",
    "mrts_data = mrts_data.drop([mrts_data.columns[0],\"Date\"], axis=1)\n",
    "mrts_data = mrts_data[:-1] # delete present month\n",
    "mrts_data[\"Year\"] = mrts_data[\"Year\"].astype(int)\n",
    "mrts_data[\"Month\"] = mrts_data[\"Month\"].apply(lambda x: months[x])\n",
    "mrts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26991470",
   "metadata": {},
   "outputs": [],
   "source": [
    "includeIndicators = True\n",
    "TestYears = [2018, 2019, 2020] #5\n",
    "NumNodes = 153 # approx 2/3 of the number of your rows. Make this divisible by a three #6\n",
    "startYear = 2002 # 7\n",
    "endYear = 2021 # 8\n",
    "startMonth = 1 # 9\n",
    "endMonth = 4 # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a790b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Every sales column in the the mrts dataset\n",
    "start = time.time()\n",
    "resultsMRTS = pd.DataFrame()\n",
    "for s, SalesColName in enumerate(mrts_data.columns):\n",
    "    if s==1:\n",
    "        break\n",
    "    # Every indicator\n",
    "    for i, indicator_file in enumerate(glob.glob(\"Data_Copy/Economic indicators/*\")):\n",
    "        ind_name = indicator_file.split(\"/\")[-1]\n",
    "        print(\"\\n----------\\n\\n\"+ind_name, SalesColName)\n",
    "\n",
    "        indicator = pd.read_csv(indicator_file)\n",
    "        indicator['Year'] = indicator['DateTime'].apply(lambda x: int(x.split(\"-\")[0]))\n",
    "        indicator['Month'] = indicator['DateTime'].apply(lambda x: int(x.split(\"-\")[1]))\n",
    "        indicator = indicator[[\"Year\", \"Month\", \"Value\"]].rename(columns={\"Value\":\"Indicator\"})\n",
    "        new_sales_col = []\n",
    "        for idx, row in indicator.iterrows():\n",
    "            try:\n",
    "                sales = mrts_data[((mrts_data['Year'] == row.Year) &\n",
    "                                   (mrts_data['Month'] == row.Month))][SalesColName].tolist()[0]\n",
    "                new_sales_col.append(sales)\n",
    "            except IndexError:\n",
    "                new_sales_col.append(sales)\n",
    "                continue\n",
    "        indicator[\"Sales\"] = new_sales_col\n",
    "        data = indicator.copy()\n",
    "        \n",
    "        for testYear in TestYears:\n",
    "            trainSet = data[data[\"Year\"]<testYear]\n",
    "            X_train = trainSet[[\"Month\", \"Year\", \"Indicator\"]].to_numpy()\n",
    "            y_train = trainSet[\"Sales\"].to_numpy()\n",
    "            \n",
    "            testSet = data[data[\"Year\"]==testYear]\n",
    "            X_test = testSet[[\"Month\", \"Year\", \"Indicator\"]].to_numpy()\n",
    "            y_test = testSet[\"Sales\"].to_numpy()\n",
    "            \n",
    "            model = create_model(NumNodes)\n",
    "            model.fit(X_train, y_train, epochs=500, batch_size=128, verbose=0) #change batch size to a variable\n",
    "    \n",
    "            # Test results from model using training data\n",
    "            y_preds = model.predict(X_test)\n",
    "            testRMSE = mean_squared_error(y_test, y_preds, squared=False)\n",
    "            trainStDev = trainSet[\"Sales\"].std()\n",
    "            evr = (trainStDev - testRMSE) / trainStDev\n",
    "               \n",
    "            currResults = {\n",
    "                \"Sales Column\": SalesColName,\n",
    "                \"Indicator\" : ind_name,\n",
    "                \"Train Year Start\": trainSet[\"Year\"].min(),\n",
    "                \"Pred Year\": int(testYear),\n",
    "                \"Train Std\": round(trainStDev, 3), \n",
    "                \"Test RMSE\": round(testRMSE, 3),\n",
    "                \"Explained Variance Ratio\": round(evr, 3)\n",
    "            }\n",
    "            resultsMRTS = resultsMRTS.append(currResults, ignore_index=True)\n",
    "        if i>3:\n",
    "            break\n",
    "                \n",
    "\n",
    "print(\"Time elapsed:\", time.time()-start)\n",
    "resultsMRTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b8473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
